{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d8bcfc",
   "metadata": {},
   "source": [
    "## Heart Disease Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae97c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score, f1_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22143938",
   "metadata": {},
   "source": [
    "**Data Source:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/45/heart+disease)\n",
    "\n",
    "**Columns in data:**\n",
    "- `age`: age in years\n",
    "- `sex`: sex (1 = male; 0 = female)\n",
    "- `cp`: chest pain type\n",
    "    - Value 1: typical angina\n",
    "    - Value 2: atypical angina\n",
    "    - Value 3: non-anginal pain\n",
    "    - Value 4: asymptomatic\n",
    "- `trestbps`: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "- `chol`: serum cholesterol in mg/dl\n",
    "- `fbs`: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "- `restecg`: resting electrocardiographic results\n",
    "    - Value 0: normal\n",
    "    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "- `thalach`: maximum heart rate achieved\n",
    "- `exang`: exercise induced angina (1 = yes; 0 = no)\n",
    "- `oldpeak`: ST depression induced by exercise relative to rest\n",
    "- `slope`: the slope of the peak exercise ST segment\n",
    "    - Value 1: upsloping\n",
    "    - Value 2: flat\n",
    "    - Value 3: downsloping\n",
    "- `ca`: number of major vessels (0-3) colored by flourosopy\n",
    "- `thal`: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "- `num`: diagnosis of heart disease (angiographic disease status)\n",
    "    - Value 0: < 50% diameter narrowing\n",
    "    - Value 1, 2, 3, or 4: > 50% diameter narrowing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf8825",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4f0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_hungary = pd.read_excel(\"hd_hungary.xlsx\", header=None)\n",
    "hd_switzerland = pd.read_excel(\"hd_switzerland.xlsx\", header=None)\n",
    "\n",
    "hd = pd.concat([hd_hungary, hd_switzerland], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf80462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp trestbps  chol fbs restecg thalach exang oldpeak slope  ca  \\\n",
       "0   40    1   2      140   289   0       0     172     0     0.0    -9  -9   \n",
       "1   49    0   3      160   180   0       0     156     0     1.0     2  -9   \n",
       "2   37    1   2      130   283   0       1      98     0     0.0    -9  -9   \n",
       "3   48    0   4      138   214   0       0     108     1     1.5     2  -9   \n",
       "4   54    1   3      150    -9   0       0     122     0     0.0    -9  -9   \n",
       "\n",
       "  thal  num  \n",
       "0   -9    0  \n",
       "1   -9    1  \n",
       "2   -9    0  \n",
       "3   -9    3  \n",
       "4   -9    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
    "\n",
    "hd.columns = colnames\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ae683",
   "metadata": {},
   "source": [
    "In the heart disease Switzerland dataset, missing values are labeled with '?' so I am going to change these to nulls instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5411782",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447340b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417 entries, 0 to 416\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       417 non-null    int64  \n",
      " 1   sex       417 non-null    int64  \n",
      " 2   cp        417 non-null    int64  \n",
      " 3   trestbps  415 non-null    float64\n",
      " 4   chol      417 non-null    int64  \n",
      " 5   fbs       342 non-null    float64\n",
      " 6   restecg   416 non-null    float64\n",
      " 7   thalach   416 non-null    float64\n",
      " 8   exang     416 non-null    float64\n",
      " 9   oldpeak   411 non-null    float64\n",
      " 10  slope     400 non-null    float64\n",
      " 11  ca        299 non-null    float64\n",
      " 12  thal      365 non-null    float64\n",
      " 13  num       417 non-null    int64  \n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 45.7 KB\n"
     ]
    }
   ],
   "source": [
    "hd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305033d5",
   "metadata": {},
   "source": [
    "I am going to drop the columns for `slope`, `ca`, and `thal` because there are too many rows with missing values (labeled as \"-9\" in `slope` and `thal`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ac6213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: slope\n",
      "-9.0    190\n",
      " 2.0    152\n",
      " 1.0     45\n",
      " 3.0     13\n",
      "Name: slope, dtype: int64\n",
      "\n",
      "Unique Values: thal\n",
      "-9.0    266\n",
      " 7.0     53\n",
      " 3.0     26\n",
      " 6.0     20\n",
      "Name: thal, dtype: int64\n",
      "\n",
      "Unique Values: chol\n",
      " 0      123\n",
      "-9       23\n",
      " 246      5\n",
      " 230      5\n",
      " 275      5\n",
      "       ... \n",
      " 85       1\n",
      " 329      1\n",
      " 210      1\n",
      " 307      1\n",
      " 466      1\n",
      "Name: chol, Length: 155, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Unique Values: slope')\n",
    "value_counts = hd['slope'].value_counts()\n",
    "\n",
    "print(value_counts)\n",
    "\n",
    "print('\\nUnique Values: thal')\n",
    "value_counts = hd['thal'].value_counts()\n",
    "\n",
    "print(value_counts)\n",
    "\n",
    "print('\\nUnique Values: chol')\n",
    "value_counts = hd['chol'].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae8b8d",
   "metadata": {},
   "source": [
    "Will also convert -9 to null values here as an extra measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80911e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.replace(-9, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df49860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "columns_to_drop = ['slope', 'ca', 'fbs', 'thal']\n",
    "\n",
    "hd = hd.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604c738",
   "metadata": {},
   "source": [
    "### Converting Columns to Categorical\n",
    "\n",
    "There are many columns here that use integer codes to label certain things. I am going to swap out these integers with the labels that they stand for. Technically, I could have just converted the integer columns into strings with numbers, but I think replacing them with the labels themselves can help with explanability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5671b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_cat(column, mapping):\n",
    "    hd[column].replace(mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de5831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['sex', 'cp', 'restecg', 'exang']\n",
    "\n",
    "cat_values = [{1: 'M', 0: 'F'},\n",
    "             {1: 'typical angina', 2: 'atypical angina', 3: 'non-anginal pain', 4: 'asymptomatic'},\n",
    "             {0: 'normal', 1: 'ST-T abnorm', 2: 'left ventricular hypertrophy'},\n",
    "             {1: 'Yes', 0: 'No'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a40c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(cat_columns)):\n",
    "    num_to_cat(cat_columns[i], cat_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe762aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>140.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>172.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>160.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>156.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>ST-T abnorm</td>\n",
       "      <td>98.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>138.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>122.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age sex                cp  trestbps   chol      restecg  thalach exang  \\\n",
       "0   40   M   atypical angina     140.0  289.0       normal    172.0    No   \n",
       "1   49   F  non-anginal pain     160.0  180.0       normal    156.0    No   \n",
       "2   37   M   atypical angina     130.0  283.0  ST-T abnorm     98.0    No   \n",
       "3   48   F      asymptomatic     138.0  214.0       normal    108.0   Yes   \n",
       "4   54   M  non-anginal pain     150.0    NaN       normal    122.0    No   \n",
       "\n",
       "   oldpeak  num  \n",
       "0      0.0    0  \n",
       "1      1.0    1  \n",
       "2      0.0    0  \n",
       "3      1.5    3  \n",
       "4      0.0    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6a298",
   "metadata": {},
   "source": [
    "I also want to replace all non-zero values with 1, to indicate heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03da132",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.loc[hd['num'] != 0, 'num'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29718b",
   "metadata": {},
   "source": [
    "### Drop null rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209424a2",
   "metadata": {},
   "source": [
    "After looking at how many null values are left, I think the amount is small enough to drop the remaining rows that contain null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69dfdb5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age          0\n",
      "sex          0\n",
      "cp           0\n",
      "trestbps     3\n",
      "chol        23\n",
      "restecg      2\n",
      "thalach      2\n",
      "exang        2\n",
      "oldpeak      6\n",
      "num          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = hd.isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f7e00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db10fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hd.drop('num', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88570db",
   "metadata": {},
   "source": [
    "### Taking one more look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad0afa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>140.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>172.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>160.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>156.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>ST-T abnorm</td>\n",
       "      <td>98.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>138.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>120.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>170.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>170.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>110.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>142.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>140.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>120.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>130.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>142.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex                cp  trestbps   chol      restecg  thalach exang  \\\n",
       "0    40   M   atypical angina     140.0  289.0       normal    172.0    No   \n",
       "1    49   F  non-anginal pain     160.0  180.0       normal    156.0    No   \n",
       "2    37   M   atypical angina     130.0  283.0  ST-T abnorm     98.0    No   \n",
       "3    48   F      asymptomatic     138.0  214.0       normal    108.0   Yes   \n",
       "5    39   M  non-anginal pain     120.0  339.0       normal    170.0    No   \n",
       "6    45   F   atypical angina     130.0  237.0       normal    170.0    No   \n",
       "7    54   M   atypical angina     110.0  208.0       normal    142.0    No   \n",
       "8    37   M      asymptomatic     140.0  207.0       normal    130.0   Yes   \n",
       "9    48   F   atypical angina     120.0  284.0       normal    120.0    No   \n",
       "10   37   F  non-anginal pain     130.0  211.0       normal    142.0    No   \n",
       "\n",
       "    oldpeak  num  \n",
       "0       0.0    0  \n",
       "1       1.0    1  \n",
       "2       0.0    0  \n",
       "3       1.5    1  \n",
       "5       0.0    0  \n",
       "6       0.0    0  \n",
       "7       0.0    0  \n",
       "8       1.5    1  \n",
       "9       0.0    0  \n",
       "10      0.0    0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9bdb6",
   "metadata": {},
   "source": [
    "### Data Balance/Imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4cb61",
   "metadata": {},
   "source": [
    "This dataset seems to be more or less balanced between 0 and 1, so I am not going to do any rebalancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3bdf34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    208\n",
       "0    177\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = hd['num']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9e3c1",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8081ada",
   "metadata": {},
   "source": [
    "### Train Validate Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1e1d9",
   "metadata": {},
   "source": [
    "First I will one-hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b0edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['sex', 'cp', 'restecg', 'exang']\n",
    "\n",
    "X = pd.get_dummies(X, columns = cat_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5595b",
   "metadata": {},
   "source": [
    "Then I can split the data (20% test, 20% validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aeb3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_temp, y_temp, test_size=0.25, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f02bd4",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4542bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_processed = scaler.fit_transform(X_train)\n",
    "\n",
    "X_validate_processed = scaler.transform(X_validate)\n",
    "\n",
    "X_test_processed = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17b3d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame(columns = ['Model', 'Accuracy', 'AUC', 'F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72340a8",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0f7c244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "logistic_regression_model.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b0dcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate_pred = logistic_regression_model.predict(X_validate_processed)\n",
    "\n",
    "lr_accuracy_score = accuracy_score(y_validate, y_validate_pred)\n",
    "lr_classification = classification_report(y_validate, y_validate_pred)\n",
    "lr_auc = roc_auc_score(y_validate, y_validate_pred)\n",
    "lr_f1 = f1_score(y_validate, y_validate_pred)\n",
    "\n",
    "model_performance.loc[len(model_performance)] = ['Logistic Regression', lr_accuracy_score, lr_auc, lr_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb765c8",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9789c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.792\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78        34\n",
      "           1       0.85      0.77      0.80        43\n",
      "\n",
      "    accuracy                           0.79        77\n",
      "   macro avg       0.79      0.80      0.79        77\n",
      "weighted avg       0.80      0.79      0.79        77\n",
      "\n",
      "Validation AUC: 0.795\n",
      "\n",
      "Validation Set F1 Score: 0.805\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Set Accuracy:\", round(lr_accuracy_score, 3))\n",
    "print(\"\\nValidation Set Classification Report:\\n\", lr_classification)\n",
    "print(\"Validation AUC:\", round(lr_auc, 3))\n",
    "print(\"\\nValidation Set F1 Score:\", round(lr_f1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a258cb",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b0c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb5136c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=0),\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=5,\n",
    "                                   random_state=0,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3619934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "best_rf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6767a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate_pred = best_rf.predict(X_validate_processed)\n",
    "\n",
    "rf_accuracy_score = accuracy_score(y_validate, y_validate_pred)\n",
    "rf_classification = classification_report(y_validate, y_validate_pred)\n",
    "rf_auc = roc_auc_score(y_validate, y_validate_pred)\n",
    "rf_f1 = f1_score(y_validate, y_validate_pred)\n",
    "\n",
    "model_performance.loc[len(model_performance)] = ['Random Forest', rf_accuracy_score, rf_auc, rf_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2ade7",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74f03692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.844\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82        34\n",
      "           1       0.84      0.88      0.86        43\n",
      "\n",
      "    accuracy                           0.84        77\n",
      "   macro avg       0.84      0.84      0.84        77\n",
      "weighted avg       0.84      0.84      0.84        77\n",
      "\n",
      "Validation AUC: 0.839\n",
      "\n",
      "Validation Set F1 Score: 0.864\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Set Accuracy:\", round(rf_accuracy_score, 3))\n",
    "print(\"\\nValidation Set Classification Report:\\n\", rf_classification)\n",
    "print(\"Validation AUC:\", round(rf_auc, 3))\n",
    "print(\"\\nValidation Set F1 Score:\", round(rf_f1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7dfeb",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abeeba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'gamma': [0, 0.1],\n",
    "    'colsample_bytree': [0.6, 0.7],\n",
    "    'subsample': [0.6, 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b063e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(xgb.XGBClassifier(objective='binary:logistic', random_state=0),\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=5,\n",
    "                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1f52a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.fit(X_train_processed, y_train)\n",
    "best_xgb = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d89f0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate_pred = best_xgb.predict(X_validate_processed)\n",
    "\n",
    "xgb_accuracy_score = accuracy_score(y_validate, y_validate_pred)\n",
    "xgb_classification = classification_report(y_validate, y_validate_pred)\n",
    "xgb_auc = roc_auc_score(y_validate, y_validate_pred)\n",
    "xgb_f1 = f1_score(y_validate, y_validate_pred)\n",
    "\n",
    "model_performance.loc[len(model_performance)] = ['XGBoost', xgb_accuracy_score, xgb_auc, xgb_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341beed",
   "metadata": {},
   "source": [
    "#### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9b77453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.818\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81        34\n",
      "           1       0.87      0.79      0.83        43\n",
      "\n",
      "    accuracy                           0.82        77\n",
      "   macro avg       0.82      0.82      0.82        77\n",
      "weighted avg       0.82      0.82      0.82        77\n",
      "\n",
      "Validation AUC:\n",
      " 0.822\n",
      "\n",
      "Validation Set F1 Score: 0.829\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Set Accuracy:\", round(xgb_accuracy_score, 3))\n",
    "print(\"\\nValidation Set Classification Report:\\n\", xgb_classification)\n",
    "print(\"Validation AUC:\\n\", round(xgb_auc, 3))\n",
    "print(\"\\nValidation Set F1 Score:\", round(xgb_f1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fddf85",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "082906b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.795486</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.838919</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.821819</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy       AUC        F1\n",
       "0  Logistic Regression  0.792208  0.795486  0.804878\n",
       "1        Random Forest  0.844156  0.838919  0.863636\n",
       "2              XGBoost  0.818182  0.821819  0.829268"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f393c0",
   "metadata": {},
   "source": [
    "The best performing model appears to be the **Random Forest**. Here are its performance metrics on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b851ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict(X_test_processed)\n",
    "\n",
    "rf_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "rf_classification = classification_report(y_test, y_pred)\n",
    "rf_auc = roc_auc_score(y_test, y_pred)\n",
    "rf_f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bddd9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.766\n",
      "\n",
      "Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67        33\n",
      "           1       0.73      0.93      0.82        44\n",
      "\n",
      "    accuracy                           0.77        77\n",
      "   macro avg       0.79      0.74      0.74        77\n",
      "weighted avg       0.79      0.77      0.75        77\n",
      "\n",
      "Validation AUC: 0.739\n",
      "\n",
      "Validation Set F1 Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Set Accuracy:\", round(rf_accuracy_score, 3))\n",
    "print(\"\\nValidation Set Classification Report:\\n\", rf_classification)\n",
    "print(\"Validation AUC:\", round(rf_auc, 3))\n",
    "print(\"\\nValidation Set F1 Score:\", round(rf_f1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc94f645",
   "metadata": {},
   "source": [
    "The Accuracy and AUC are quite a bit worse in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac853e",
   "metadata": {},
   "source": [
    "## Investigating Overfitting, maybe RandomSearch is too much?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f393d273",
   "metadata": {},
   "source": [
    "Because the data size is relatively small, I think that hyperparameter tuning these models is overfitting on the validate data. I am going to rerun these models without using random search.\n",
    "\n",
    "I never did random search on logistic regression originally, so I am going to remove the random search from random forest and xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ae0a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_2 = pd.DataFrame(columns = ['Model', 'Accuracy', 'AUC', 'F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6c35e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69b21fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "logistic_regression_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_validate_pred = logistic_regression_model.predict(X_validate_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eac2e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy_score = accuracy_score(y_validate, y_validate_pred)\n",
    "lr_classification = classification_report(y_validate, y_validate_pred)\n",
    "lr_auc = roc_auc_score(y_validate, y_validate_pred)\n",
    "lr_f1 = f1_score(y_validate, y_validate_pred)\n",
    "\n",
    "model_performance_2.loc[len(model_performance_2)] = ['Logistic Regression', lr_accuracy_score, lr_auc, lr_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcb376",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04ef1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=14)\n",
    "random_forest_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_validate_pred = random_forest_model.predict(X_validate_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04aaead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy_score = accuracy_score(y_validate, y_validate_pred)\n",
    "rf_classification = classification_report(y_validate, y_validate_pred)\n",
    "rf_auc = roc_auc_score(y_validate, y_validate_pred)\n",
    "rf_f1 = f1_score(y_validate, y_validate_pred)\n",
    "\n",
    "model_performance_2.loc[len(model_performance_2)] = ['Random Forest', rf_accuracy_score, rf_auc, rf_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cb189",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b91bd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier(n_estimators=100, random_state=14)\n",
    "xgboost_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_validate_pred = xgboost_model.predict(X_validate_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d453f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_accuracy_score = accuracy_score(y_validate, y_validate_pred)\n",
    "xgb_classification = classification_report(y_validate, y_validate_pred)\n",
    "xgb_auc = roc_auc_score(y_validate, y_validate_pred)\n",
    "xgb_f1 = f1_score(y_validate, y_validate_pred)\n",
    "\n",
    "model_performance_2.loc[len(model_performance_2)] = ['XGBoost', xgb_accuracy_score, xgb_auc, xgb_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653a88c",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "473850be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.795486</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.841997</td>\n",
       "      <td>0.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.751368</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy       AUC        F1\n",
       "0  Logistic Regression  0.792208  0.795486  0.804878\n",
       "1        Random Forest  0.844156  0.841997  0.860465\n",
       "2              XGBoost  0.753247  0.751368  0.776471"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09025208",
   "metadata": {},
   "source": [
    "Random forest still performs the best, let's compare to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0b960",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74aa9109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.779\n",
      "\n",
      "Test Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.58      0.69        33\n",
      "           1       0.75      0.93      0.83        44\n",
      "\n",
      "    accuracy                           0.78        77\n",
      "   macro avg       0.80      0.75      0.76        77\n",
      "weighted avg       0.80      0.78      0.77        77\n",
      "\n",
      "Test AUC: 0.754\n",
      "\n",
      "Test Set F1 Score: 0.828\n"
     ]
    }
   ],
   "source": [
    "y_pred = random_forest_model.predict(X_test_processed)\n",
    "\n",
    "rf_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "rf_classification = classification_report(y_test, y_pred)\n",
    "rf_auc = roc_auc_score(y_test, y_pred)\n",
    "rf_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Set Accuracy:\", round(rf_accuracy_score, 3))\n",
    "print(\"\\nTest Set Classification Report:\\n\", rf_classification)\n",
    "print(\"Test AUC:\", round(rf_auc, 3))\n",
    "print(\"\\nTest Set F1 Score:\", round(rf_f1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc8ab4",
   "metadata": {},
   "source": [
    "AUC and accuracy still drop here. I think that the small sample size is leading to overfitting on my train data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
